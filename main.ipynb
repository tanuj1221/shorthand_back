{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanuj\\AppData\\Local\\Temp\\ipykernel_26840\\734134811.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from requests_html import AsyncHTMLSession\n",
    "import asyncio\n",
    "# from requests_html import HTMLSession\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import traceback\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "#from concurrent.futures import ThreadPoolExecutor\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>agilent-technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>alcoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>ata-creativity-global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ata-creativity-global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AADI</td>\n",
       "      <td>aadi-bioscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>ZVRA</td>\n",
       "      <td>zevra-therapeutics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>ZWS</td>\n",
       "      <td>zurn-water-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>zymeworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>zynerba-pharmaceuticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>zynex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol                      name\n",
       "0         A      agilent-technologies\n",
       "1        AA                     alcoa\n",
       "2       AAC     ata-creativity-global\n",
       "3      AACG     ata-creativity-global\n",
       "4      AADI           aadi-bioscience\n",
       "...     ...                       ...\n",
       "4952   ZVRA        zevra-therapeutics\n",
       "4953    ZWS      zurn-water-solutions\n",
       "4954   ZYME                 zymeworks\n",
       "4955   ZYNE   zynerba-pharmaceuticals\n",
       "4956   ZYXI                     zynex\n",
       "\n",
       "[4957 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session=AsyncHTMLSession()\n",
    "\n",
    "#Loading ticker data from the CSV\n",
    "df=pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=len(df['Symbol'])\n",
    "symbol=\"\"\n",
    "perpetual_growth_rate=0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------------------------#\n",
    "#                           Required custom functions                               #\n",
    "#-----------------------------------------------------------------------------------#\n",
    "def to_float(valueo:str):\n",
    "    try:\n",
    "        value=valueo.strip().replace(\" \",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace(\"%\",\"\")\n",
    "        if \"M\" in value:\n",
    "            value=float(value.replace(\"M\",\"\"))*1000000\n",
    "            return value\n",
    "        elif \"B\" in value:\n",
    "            value=float(value.replace(\"B\",\"\"))*1000000000\n",
    "            return value\n",
    "        elif \"T\" in value:\n",
    "            value=float(value.replace(\"T\",\"\"))*1000000000000\n",
    "            return value\n",
    "        else:\n",
    "            return float(value)\n",
    "    except:\n",
    "        return 0\n",
    "#------------------------------------------------------------------------------#\n",
    "def to_int(valueo:str):\n",
    "    try:\n",
    "        value=valueo.strip().replace(\" \",\"\").replace(\",\",\"\").replace(\"$\",\"\").replace(\"%\",\"\")\n",
    "        if \"M\" in value:\n",
    "            value=int(value.replace(\"M\",\"\"))*1000000\n",
    "            return value\n",
    "        elif \"B\" in value:\n",
    "            value=int(value.replace(\"B\",\"\"))*1000000000\n",
    "            return value\n",
    "        elif \"T\" in value:\n",
    "            value=int(value.replace(\"T\",\"\"))*1000000000000\n",
    "            return value\n",
    "        else:\n",
    "            return int(value)\n",
    "    except:\n",
    "        return 0\n",
    "#--------------------------------------------------------------------------------------#\n",
    "async def get_cashflow():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}/cash-flow\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        row = soup.find('div', {'title': 'Free Cash Flow'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        columns=row.findAll('div', {'data-test': 'fin-col'})\n",
    "\n",
    "        data={\n",
    "            \"FCF 2023\":to_int(columns[1].text)*1000,\n",
    "            \"FCF 2022\":to_int(columns[2].text)*1000,\n",
    "            \"FCF 2021\":to_int(columns[3].text)*1000,\n",
    "            \"FCF 2020\":to_int(columns[4].text)*1000,\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "    \n",
    "async def get_balanceSheet():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}/balance-sheet\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        TotalDebt = soup.find('div', {'title': 'Total Debt'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        TotalDebt=TotalDebt.findAll('div', {'data-test': 'fin-col'})[1].text\n",
    "        # row = soup.findAll('div', {'data-test': 'fin-row'})[10]\n",
    "        # columns=row.findAll('div', {'data-test': 'fin-col'})\n",
    "\n",
    "        data={\n",
    "            \"Total Debt\":to_int(TotalDebt)*1000,\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "async def get_analysis():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}/analysis\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        analysis = soup.find('section', {'data-test': 'qsp-analyst'})\n",
    "        growth=analysis.find_all(\"table\")[-1]\n",
    "        rows=growth.find(\"tbody\").find_all(\"tr\")\n",
    "        data={}\n",
    "        data[\"Next Year\"]=rows[3].find_all(\"td\")[1].text\n",
    "        data[\"Next 5Year\"]=rows[4].find_all(\"td\")[1].text\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "async def get_stats():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}/key-statistics\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        stats = soup.find('section', {'data-test': 'qsp-statistics'})\n",
    "        share_stats=stats.find_all(\"table\")[2]\n",
    "        share_out=share_stats.find(\"tbody\").find_all(\"tr\")[2].find_all(\"td\")[1]\n",
    "\n",
    "        ROE_stats=stats.find_all(\"table\")[6]\n",
    "        ROE_out=ROE_stats.find(\"tbody\").find_all(\"tr\")[1].find_all(\"td\")[1]\n",
    "        data={}\n",
    "        data[\"Share Outstandings\"]=to_float(share_out.text)\n",
    "        data[\"Return on Equity (ttm)\"]=to_float(ROE_out.text)/100\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "async def get_financials():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}/financials\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        financials = soup.find('section', {'data-test': 'qsp-financial'})\n",
    "        row = financials.find('div', {'title': 'Diluted EPS'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        columns=row.findAll('div', {'data-test': 'fin-col'})\n",
    "        InterestExpense = financials.find('div', {'title': 'Interest Expense'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        InterestExpense=InterestExpense.findAll('div', {'data-test': 'fin-col'})[1].text\n",
    "        IncomeTaxExpense=financials.find('div', {'title': 'Tax Provision'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        IncomeTaxExpense=IncomeTaxExpense.findAll('div', {'data-test': 'fin-col'})[1].text\n",
    "        Incomebeforetax=financials.find('div', {'title': 'Pretax Income'}).findPrevious('div',{'data-test': 'fin-row'})\n",
    "        Incomebeforetax=Incomebeforetax.findAll('div', {'data-test': 'fin-col'})[1].text\n",
    "        data={\n",
    "            \"Eps Diluted 2024\":float(columns[0].text),\n",
    "            \"Eps Diluted 2023\":float(columns[1].text),\n",
    "            \"Eps Diluted 2022\":float(columns[2].text),\n",
    "            \"Eps Diluted 2021\":float(columns[3].text),\n",
    "            \"Eps Diluted 2020\":float(columns[4].text),\n",
    "        }\n",
    "        if data['Eps Diluted 2020']>0 and data['Eps Diluted 2021']>0 and data['Eps Diluted 2022']>0 and data['Eps Diluted 2023']>0 and data['Eps Diluted 2024']>0:\n",
    "            pass\n",
    "        else:\n",
    "            data['reason']=\"negative EPS\"\n",
    "        data['Eps Diluted 2023%']=(data['Eps Diluted 2023']-data['Eps Diluted 2022'])/data['Eps Diluted 2022']\n",
    "        data['Eps Diluted 2022%']=(data['Eps Diluted 2022']-data['Eps Diluted 2021'])/data['Eps Diluted 2021']\n",
    "        data['Eps Diluted 2021%']=(data['Eps Diluted 2021']-data['Eps Diluted 2020'])/data['Eps Diluted 2020']\n",
    "        sum=0\n",
    "        # for each in data:\n",
    "        #     sum=sum+data[each]\n",
    "        # average_eps=sum/len(data)\n",
    "        data['EPS rate%']=((data['Eps Diluted 2023%']+data['Eps Diluted 2022%']+data['Eps Diluted 2021%'])/3)\n",
    "\n",
    "        data['Interest Expense']=to_int(InterestExpense)*1000\n",
    "        data['Income Tax Expense']=to_int(IncomeTaxExpense)*1000\n",
    "        data['Income before tax']=to_int(Incomebeforetax)*1000\n",
    "        data['Effective tax rate (in %)']=int(IncomeTaxExpense.replace(\",\",\"\"))/int(Incomebeforetax.replace(\",\",\"\"))/100\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "async def get_data_summary():\n",
    "    data={}\n",
    "    try:\n",
    "        res=await session.get(f\"https://finance.yahoo.com/quote/{symbol}\")\n",
    "        await res.html.arender(timeout=10000)\n",
    "        soup=bs(res.content,'html.parser')\n",
    "        data={\n",
    "            \"Price\":to_float(get_price(soup)),\n",
    "            \"PE Ratio\":to_float(get_pe_ratio(soup)),\n",
    "            \"EPS(TTM)\":to_float(get_eps_ratio(soup)),\n",
    "            \"Beta\":to_float(get_beta(soup)),\n",
    "            \"Market Cap\":to_float(get_market_cap(soup))\n",
    "        }\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        td_tag = soup.find('td', {'data-test': 'PREV_CLOSE-value'})\n",
    "        return td_tag.text\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "#--------------------------------------------------------------------------------------#\n",
    "def get_pe_ratio(soup):\n",
    "    try:\n",
    "        td_tag = soup.find('td', {'data-test': 'PE_RATIO-value'})\n",
    "        return td_tag.text\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "#--------------------------------------------------------------------------------------#\n",
    "def get_eps_ratio(soup):\n",
    "    try:\n",
    "        td_tag = soup.find('td', {'data-test': 'EPS_RATIO-value'})\n",
    "        return td_tag.text\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "#--------------------------------------------------------------------------------------#\n",
    "def get_beta(soup):\n",
    "    try:\n",
    "        td_tag = soup.find('td', {'data-test': 'BETA_5Y-value'})\n",
    "        return td_tag.text\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "#--------------------------------------------------------------------------------------#\n",
    "def get_market_cap(soup):\n",
    "    try:\n",
    "        td_tag = soup.find('td', {'data-test': 'MARKET_CAP-value'})\n",
    "        return td_tag.text\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "async def get_cash_on_hand():\n",
    "    try:\n",
    "        s=ticker[f\"{symbol}\"].lower()\n",
    "        headers = {\n",
    "    # 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Accept-Language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    # 'Cache-Control': 'max-age=0',\n",
    "    # 'Cookie': 'usprivacy=1---; _jsuid=3299131652; _gd_visitor=fa33abaa-1039-4531-8883-ad6bbe144f25; _gd_svisitor=65f06e68b23a1c00d1a0ad64e80000009d480100; __qca=P0-717079984-1708790328855; cnx_userId=2e953735fd05415cbac2a73f839f4337; _cc_id=a74bb47423820f64ef9eb6e6192b979f; panoramaId_expiry=1709395152451; panoramaId=98ed3cc483515500cf7e078beefc4945a70221d4cf3341b92af7778bac4a36b3; panoramaIdType=panoIndiv; cf_clearance=d_4Z3s3mOj_nQquUAkC5Q.JRF8vJ.Z7Y6Z8PlSlynLY-1709042877-1.0-AWpwemo1yV5Rkq8HrkFiDH/mX+/M0RrnTHvWAGN/3udwiSL1RUt7Ww+uazNdW3sP8KsiYaBCZLSpJ+NDIRpx4oM=; _gid=GA1.2.1071979747.1709132954; _ga=GA1.1.1218498466.1708790319; cto_bundle=qFZ19F9TZSUyRjYyTHBNQ3BjRlI4V0hzVG1HUXplSEFVRXhhTWNhNDU0Tmo5MFRBa2xPZWxQYTl3VFM0R2wwSXpQZiUyQkx2OVVPblVLdmNyenQlMkZqRnhhSEFQNU5EeDFDUTlzbTBDNjhER252OFUzQllkeTZnR1olMkZNOWhzJTJCS0thcU5pZXBvRWRiOFJyZHBBNTVrQmxCa0dRZDFPaUhocm9jSE1hNmczRm9mUW1rZExEY2VFJTNE; _gd_session=c3a59520-bdeb-4aa3-8b66-3b6579e3289e; __cf_bm=q2A8MMRywMty0bumNcft945PJdBWD_xkQ_cIfMEmKdw-1709135150-1.0-AVOVwzHVlpEF8yrOy1kY7die3MoHWDWpEZ2ErcSckdbd6tgToPAmTYoeCjhsMDLJYwA4IhGLIIHacLOkRVnwvsY=; _ga_3KL0LYERBH=GS1.1.1709132122.6.1.1709135153.54.0.0; IC_ViewCounter_www.macrotrends.net=2; _awl=2.1709135154.5-94859f662a79cc15aeb732e4e6c6195c-6763652d617369612d6561737431-0; __gads=ID=c5dccd64ce225151:T=1708790343:RT=1709135780:S=ALNI_Mbm58BmNA1bllCyPNA0nWxfkUu1Dg; __gpi=UID=00000d13de8a691d:T=1708790343:RT=1709135780:S=ALNI_MZR6K4TSMO0Pn_3Pd1GjxZu5Z1K-A; __eoi=ID=8bdae96c8575d5cb:T=1708790343:RT=1709135780:S=AA-Afja5M66NSTrC2kzWZqTzXBCk; __cf_bm=LhvvyEHF.koOjkT5Pb18zYeaCNQShMRWb5FYgiaHGCk-1709143181-1.0-AWbTZU8EfeGzz9x1vY8b8q/3HSqyWcLSBKaPGkc4zEFoTQ8G5iCsYVouGAjG83TaOqGrFp+CN+tXsHozERPK7IU=',\n",
    "    # 'If-Modified-Since': 'Wed, 28 Feb 2024 10:57:34 GMT',\n",
    "    'Referer': f'https://www.macrotrends.net/stocks/charts/{symbol}/{s}/other-current-assets',\n",
    "    'Sec-Ch-Ua': '\"Not A(Brand\";v=\"99\", \"Google Chrome\";v=\"121\", \"Chromium\";v=\"121\"',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "    }\n",
    "        url=f\"https://www.macrotrends.net/stocks/charts/{s}/cash-on-hand\"\n",
    "        print(url)\n",
    "        session1 = requests.Session()\n",
    "        request = session1.get(url,headers=headers)\n",
    "        cookies = dict(request.cookies)\n",
    "        j=0\n",
    "        while True:\n",
    "            j+=1\n",
    "            res= await session.get(url,headers=headers,timeout=10000,cookies=cookies)\n",
    "            await res.html.arender(timeout=10000)\n",
    "            cash_on_hand=bs(res.content,\"html.parser\")\n",
    "            table=cash_on_hand.find(\"table\",{'class':'historical_data_table table'})\n",
    "            if table is not None:\n",
    "                cash=table.find(\"tbody\").find('tr').find_all('td')[1].text\n",
    "                data={}\n",
    "                data['Cash/ Cash Equivalent']=to_int(cash)*1000000\n",
    "                print(data)\n",
    "                return data\n",
    "            if j>10:\n",
    "                data={}\n",
    "                data['Cash/ Cash Equivalent']=0\n",
    "                return data\n",
    "            await asyncio.sleep(1)\n",
    "            \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Cash/cash equivalent error\",e,res.content)\n",
    "        data={}\n",
    "        data['Cash/ Cash Equivalent']=0\n",
    "        return data\n",
    "#--------------------------------------------------------------------------------------#\n",
    "\n",
    "result_bl=[]\n",
    "result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently processing: 0\n",
      "A  agilent-technologies\n",
      "This event loop is already running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tanuj\\AppData\\Local\\Temp\\ipykernel_26840\\1727798718.py\", line 12, in <module>\n",
      "    out=session.run(get_data_summary,get_cashflow,get_stats,get_analysis,get_financials,get_balanceSheet,get_cash_on_hand)\n",
      "  File \"c:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests_html.py\", line 774, in run\n",
      "    done, _ = self.loop.run_until_complete(asyncio.wait(tasks))\n",
      "  File \"c:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 618, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"c:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 578, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(session.run(get_stats))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# out=session.run(get_data_summary)+session.run(get_cashflow)+session.run(get_stats)+session.run(get_analysis)+session.run(get_financials)+session.run(get_balanceSheet)+session.run(get_cash_on_hand)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_data_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_cashflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_analysis\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_financials\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_balanceSheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_cash_on_hand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#out=asyncio.run(get_data_summary(),get_cashflow(),get_stats(),get_analysis(),get_financials(),get_balanceSheet(),get_cash_on_hand())\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests_html.py:774\u001b[0m, in \u001b[0;36mAsyncHTMLSession.run\u001b[1;34m(self, *coros)\u001b[0m\n\u001b[0;32m    771\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    772\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mensure_future(coro()) \u001b[38;5;28;01mfor\u001b[39;00m coro \u001b[38;5;129;01min\u001b[39;00m coros\n\u001b[0;32m    773\u001b[0m ]\n\u001b[1;32m--> 774\u001b[0m done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [t\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m done]\n",
      "File \u001b[1;32mc:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py:618\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 618\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n",
      "File \u001b[1;32mc:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py:578\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m    142\u001b[0m traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m--> 143\u001b[0m \u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m    144\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyppeteer\\util.py:29: RuntimeWarning: coroutine 'wait' was never awaited\n",
      "  gc.collect()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-11' coro=<get_cash_on_hand() done, defined at C:\\Users\\Tanuj\\AppData\\Local\\Temp\\ipykernel_26840\\353850992.py:212> exception=UnboundLocalError(\"local variable 'res' referenced before assignment\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tanuj\\AppData\\Local\\Temp\\ipykernel_26840\\353850992.py\", line 214, in get_cash_on_hand\n",
      "    s=ticker[f\"{symbol}\"].lower()\n",
      "NameError: name 'ticker' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tanuj\\AppData\\Local\\Temp\\ipykernel_26840\\353850992.py\", line 259, in get_cash_on_hand\n",
      "    print(\"Cash/cash equivalent error\",e,res.content)\n",
      "UnboundLocalError: local variable 'res' referenced before assignment\n",
      "[INFO] Starting Chromium download.\n",
      "[INFO] Starting Chromium download.\n",
      "[INFO] Starting Chromium download.\n",
      "[INFO] Starting Chromium download.\n",
      "[INFO] Starting Chromium download.\n",
      "[INFO] Starting Chromium download.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Iterate over n number of stocks from the stocks csv file\n",
    "for i in range(total):\n",
    "#for i in range(10):\n",
    "    print(\"currently processing:\",i)\n",
    "    try:\n",
    "        symbol=df['Symbol'][i]\n",
    "        #Getting data from yahoo finance\n",
    "        print(df['Symbol'][i],df[\"name\"][i])\n",
    "        time.sleep(1)\n",
    "        # print(session.run(get_stats))\n",
    "        # out=session.run(get_data_summary)+session.run(get_cashflow)+session.run(get_stats)+session.run(get_analysis)+session.run(get_financials)+session.run(get_balanceSheet)+session.run(get_cash_on_hand)\n",
    "        out=session.run(get_data_summary,get_cashflow,get_stats,get_analysis,get_financials,get_balanceSheet,get_cash_on_hand)\n",
    "        #out=asyncio.run(get_data_summary(),get_cashflow(),get_stats(),get_analysis(),get_financials(),get_balanceSheet(),get_cash_on_hand())\n",
    "        \n",
    "        data={\n",
    "            \"Stock Name\":df[\"name\"][i].upper(),\n",
    "            \"Symbol\":df['Symbol'][i]\n",
    "            }\n",
    "        url = f\"https://production.dataviz.cnn.io/quote/forecast/{symbol}\"\n",
    "        url2 = f\"https://production.dataviz.cnn.io/quote/analystratings/{symbol}\"\n",
    "        headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.106 Safari/537.36',\n",
    "                   'accept-language': 'en,gu;q=0.9,hi;q=0.8',\n",
    "                   'accept-encoding': 'gzip, deflate, br'}\n",
    "        \n",
    "        #Building Data for EPS and DCF\n",
    "        for each in out:\n",
    "            data=data|each\n",
    "        data['FCF 2024']=data['FCF 2023']*(1+(float(data['Next Year'].removesuffix(\"%\"))/100))\n",
    "        data['FFCF 2024']=data['FCF 2023']*(1+(float(data['Next 5Year'].removesuffix(\"%\"))/100))\n",
    "        data['FFCF 2025']=data['FFCF 2024']*(1+(float(data['Next 5Year'].removesuffix(\"%\"))/100))\n",
    "        data['FFCF 2026']=data['FFCF 2025']*(1+(float(data['Next 5Year'].removesuffix(\"%\"))/100))\n",
    "        data['FFCF 2027']=data['FFCF 2026']*(1+(float(data['Next 5Year'].removesuffix(\"%\"))/100))\n",
    "        data['FFCF 2028']=data['FFCF 2027']*(1+(float(data['Next 5Year'].removesuffix(\"%\"))/100))\n",
    "        data['Cost of Debt (in %)']=(data['Interest Expense']/data['Total Debt'])\n",
    "        data['Cost of debt after tax(in %)']=(float(data['Cost of Debt (in %)'])*(1+float(data['Effective tax rate (in %)'])))\n",
    "        data['Risk Free rate( in %)']=0.0425\n",
    "        data['Market Return (in %)']=0.09\n",
    "        data['Cost of equity (in %)']=(data['Risk Free rate( in %)']+((data['Beta'])*(data['Market Return (in %)']-data['Risk Free rate( in %)'])))\n",
    "        data['Total']=data['Total Debt']+data['Market Cap']\n",
    "        data['Weigh of debt(in %)']=(data['Total Debt']/data['Total'])\n",
    "        data['Weight of equity(in %)']=(data['Market Cap']/data['Total'])\n",
    "        data['WACC']=(float(data['Cost of Debt (in %)'])*(data['Weigh of debt(in %)']))+(data['Cost of equity (in %)']*data['Weight of equity(in %)'])\n",
    "        data['Terminal Value']=data['FFCF 2028']*(1+perpetual_growth_rate)/(data['WACC']-perpetual_growth_rate)\n",
    "        data['PV of FFCF 2024']=data['FFCF 2024']/(1+data['WACC'])**1\n",
    "        data['PV of FFCF 2025']=data['FFCF 2025']/(1+data['WACC'])**2\n",
    "        data['PV of FFCF 2026']=data['FFCF 2026']/(1+data['WACC'])**3\n",
    "        data['PV of FFCF 2027']=data['FFCF 2027']/(1+data['WACC'])**4\n",
    "        data['PV of FFCF 2028']=data['FFCF 2028']/(1+data['WACC'])**5\n",
    "        data['PV of Terminal Value']=data['Terminal Value']/(1+data['WACC'])**6\n",
    "        data['Sum of PV of FFCF']=data['PV of FFCF 2024']+data['PV of FFCF 2025']+data['PV of FFCF 2026']+data['PV of FFCF 2027']+data['PV of FFCF 2028']+data['PV of Terminal Value']\n",
    "        data['Equity Value']=data['Sum of PV of FFCF']+data['Cash/ Cash Equivalent']-data[\"Total Debt\"]\n",
    "        data['Price per share(Intrinsic Value via DCF)']=data['Equity Value']/data[\"Share Outstandings\"]\n",
    "        data['Perpetual Growth rate']=perpetual_growth_rate\n",
    "        data[\"Graham Formula / Intrinsic value using EPS\"]=(8.5+(data['EPS rate%'])*100)*data['EPS(TTM)']\n",
    "        data['Over/Undervalue %']=(data['Price']-data['Graham Formula / Intrinsic value using EPS'])/data['Graham Formula / Intrinsic value using EPS']\n",
    "        try:\n",
    "            session1 = requests.Session()\n",
    "            request = session1.get(url,headers=headers)\n",
    "            request2 = session1.get(url2,headers=headers)\n",
    "            cookies = dict(request.cookies)\n",
    "            cookies2 = dict(request2.cookies)\n",
    "            response = session1.get(url, headers=headers, cookies=cookies).json()\n",
    "            response2 = session1.get(url2, headers=headers, cookies=cookies2).json()\n",
    "            rdata = json.dumps(response)\n",
    "            rdata2 = json.dumps(response2)\n",
    "            json_data = json.loads(rdata)\n",
    "            json_data2 = json.loads(rdata2)\n",
    "            data1 = json_data[0]\n",
    "            data2 = json_data2[0]\n",
    "            data['High']=data1['high_target_price']\n",
    "            data['Median']=data1['median_target_price']\n",
    "            data['Low']=data1['low_target_price']\n",
    "            data['Last']=data1['current_stock_price']\n",
    "            data['Sym']=data1['symbol']\n",
    "            data['Anal']=data2[\"num_of_analysts\"]\n",
    "        except:\n",
    "            pass\n",
    "        print(data)\n",
    "        result.append(data)\n",
    "    \n",
    "        #Building data for best line method\n",
    "        data_bl=data.copy()\n",
    "        data_bl['FCF 2024']=data_bl['FCF 2023']*(1+(float(data_bl['Next Year'].removesuffix(\"%\"))/100))\n",
    "        years=np.array([2020,2021,2022,2023])\n",
    "        values=np.array([int(data_bl['FCF 2020']),int(data_bl['FCF 2021']),int(data_bl['FCF 2022']),int(data_bl['FCF 2023'])])\n",
    "        slope,intercept,r_value,p_value,std_err=linregress(years,values)\n",
    "        data_bl['M']=slope\n",
    "        data_bl['FFCF 2024']=data_bl['FCF 2023']+slope\n",
    "        data_bl['FFCF 2025']=data_bl['FFCF 2024']+slope\n",
    "        data_bl['FFCF 2026']=data_bl['FFCF 2025']+slope\n",
    "        data_bl['FFCF 2027']=data_bl['FFCF 2026']+slope\n",
    "        data_bl['FFCF 2028']=data_bl['FFCF 2027']+slope\n",
    "        data_bl['Cost of Debt (in %)']=(data_bl['Interest Expense']/data_bl['Total Debt'])\n",
    "        data_bl['Cost of debt after tax(in %)']=(float(data_bl['Cost of Debt (in %)'])*(1+float(data_bl['Effective tax rate (in %)'])))\n",
    "        data_bl['Risk Free rate( in %)']=0.0425\n",
    "        data_bl['Market Return (in %)']=0.09\n",
    "        data_bl['Cost of equity (in %)']=(data_bl['Risk Free rate( in %)']+((data_bl['Beta'])*(data_bl['Market Return (in %)']-data_bl['Risk Free rate( in %)'])))\n",
    "        data_bl['Total']=data_bl['Total Debt']+data_bl['Market Cap']\n",
    "        data_bl['Weigh of debt(in %)']=(data_bl['Total Debt']/data_bl['Total'])\n",
    "        data_bl['Weight of equity(in %)']=(data_bl['Market Cap']/data_bl['Total'])\n",
    "        data_bl['WACC']=(float(data_bl['Cost of Debt (in %)'])*(data_bl['Weigh of debt(in %)']))+(data_bl['Cost of equity (in %)']*data_bl['Weight of equity(in %)'])\n",
    "        data_bl['Terminal Value']=data_bl['FFCF 2028']*(1+perpetual_growth_rate)/(data_bl['WACC']-perpetual_growth_rate)\n",
    "        data_bl['PV of FFCF 2024']=data_bl['FFCF 2024']/(1+data_bl['WACC'])**1\n",
    "        data_bl['PV of FFCF 2025']=data_bl['FFCF 2025']/(1+data_bl['WACC'])**2\n",
    "        data_bl['PV of FFCF 2026']=data_bl['FFCF 2026']/(1+data_bl['WACC'])**3\n",
    "        data_bl['PV of FFCF 2027']=data_bl['FFCF 2027']/(1+data_bl['WACC'])**4\n",
    "        data_bl['PV of FFCF 2028']=data_bl['FFCF 2028']/(1+data_bl['WACC'])**5\n",
    "        data_bl['PV of Terminal Value']=data_bl['Terminal Value']/(1+data_bl['WACC'])**6\n",
    "        data_bl['Sum of PV of FFCF']=data_bl['PV of FFCF 2024']+data_bl['PV of FFCF 2025']+data_bl['PV of FFCF 2026']+data_bl['PV of FFCF 2027']+data_bl['PV of FFCF 2028']+data_bl['PV of Terminal Value']\n",
    "        data_bl['Equity Value']=data_bl['Sum of PV of FFCF']+data_bl['Cash/ Cash Equivalent']-data_bl[\"Total Debt\"]\n",
    "        data_bl['Price per share(Intrinsic Value via DCF)']=data_bl['Equity Value']/data_bl[\"Share Outstandings\"]\n",
    "\n",
    "        data_bl[\"Graham Formula / Intrinsic value using EPS\"]=(8.5+(data_bl['EPS rate%'])*100)*data_bl['EPS(TTM)']\n",
    "        data_bl['Over/Undervalue %']=(data_bl['Price']-data_bl['Graham Formula / Intrinsic value using EPS'])/data_bl['Graham Formula / Intrinsic value using EPS']\n",
    "        try:\n",
    "            session1 = requests.Session()\n",
    "            request = session1.get(url,headers=headers)\n",
    "            request2 = session1.get(url2,headers=headers)\n",
    "            cookies = dict(request.cookies)\n",
    "            cookies2 = dict(request2.cookies)\n",
    "            response = session1.get(url, headers=headers, cookies=cookies).json()\n",
    "            response2 = session1.get(url2, headers=headers, cookies=cookies2).json()\n",
    "            rdata_bl = json.dumps(response)\n",
    "            rdata_bl2 = json.dumps(response2)\n",
    "            json_data_bl = json.loads(rdata_bl)\n",
    "            json_data_bl2 = json.loads(rdata_bl2)\n",
    "            data_bl1 = json_data_bl[0]\n",
    "            data_bl2 = json_data_bl2[0]\n",
    "            data_bl['High']=data_bl1['high_target_price']\n",
    "            data_bl['Median']=data_bl1['median_target_price']\n",
    "            data_bl['Low']=data_bl1['low_target_price']\n",
    "            data_bl['Last']=data_bl1['current_stock_price']\n",
    "            data_bl['Sym']=data_bl1['symbol']\n",
    "            data_bl['Anal']=data_bl2[\"num_of_analysts\"]\n",
    "        except:\n",
    "            pass\n",
    "        print(data_bl)\n",
    "        result_bl.append(data_bl)\n",
    "    #Any error with the previous stock move to next with remarks\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "        data['reason']=e\n",
    "        result.append(data)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Over/Undervalue %'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Converting EPS/DCF data to dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOver/Undervalue \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOver/Undervalue \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.2%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x))\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight of equity(in \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight of equity(in \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.2%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x))\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeigh of debt(in \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeigh of debt(in \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.2%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x))\n",
      "File \u001b[1;32mc:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Tanuj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Over/Undervalue %'"
     ]
    }
   ],
   "source": [
    "\n",
    "#Converting EPS/DCF data to dataframe\n",
    "df=pd.DataFrame(result)\n",
    "df['Over/Undervalue %'] = df['Over/Undervalue %'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Weight of equity(in %)'] = df['Weight of equity(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Weigh of debt(in %)'] = df['Weigh of debt(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Cost of equity (in %)'] = df['Cost of equity (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Market Return (in %)'] = df['Market Return (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Risk Free rate( in %)'] = df['Risk Free rate( in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Cost of debt after tax(in %)'] = df['Cost of debt after tax(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Cost of Debt (in %)'] = df['Cost of Debt (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Effective tax rate (in %)'] = df['Effective tax rate (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['EPS rate%'] = df['EPS rate%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Return on Equity (ttm)'] = df['Return on Equity (ttm)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Eps Diluted 2023%'] = df['Eps Diluted 2023%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Eps Diluted 2022%'] = df['Eps Diluted 2022%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df['Eps Diluted 2021%'] = df['Eps Diluted 2021%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "\n",
    "#converting result for best line method to dataframe\n",
    "df_bl=pd.DataFrame(result_bl)\n",
    "df_bl['Over/Undervalue %'] = df_bl['Over/Undervalue %'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Weight of equity(in %)'] = df_bl['Weight of equity(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Weigh of debt(in %)'] = df_bl['Weigh of debt(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Cost of equity (in %)'] = df_bl['Cost of equity (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Market Return (in %)'] = df_bl['Market Return (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Risk Free rate( in %)'] = df_bl['Risk Free rate( in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Cost of debt after tax(in %)'] = df_bl['Cost of debt after tax(in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Cost of Debt (in %)'] = df_bl['Cost of Debt (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Effective tax rate (in %)'] = df_bl['Effective tax rate (in %)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['EPS rate%'] = df_bl['EPS rate%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Return on Equity (ttm)'] = df_bl['Return on Equity (ttm)'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Eps Diluted 2023%'] = df_bl['Eps Diluted 2023%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Eps Diluted 2022%'] = df_bl['Eps Diluted 2022%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "df_bl['Eps Diluted 2021%'] = df_bl['Eps Diluted 2021%'].apply(lambda x: '{:.2%}'.format(x))\n",
    "\n",
    "#==========================================================================================================#\n",
    "#                                              Saving Data to Excel file                                   #\n",
    "#==========================================================================================================#\n",
    "excel_file=\"DCF_result_full_new_final.xlsx\"\n",
    "\n",
    "# print(df)\n",
    "# quit()\n",
    "#Sheet 1\n",
    "#-------------------------------------Positive EPS-----------------------------#\n",
    "filtered_df = df[(df['Eps Diluted 2020'] > 0) & (df['Eps Diluted 2021'] > 0) & (df['Eps Diluted 2022'] > 0)& (df['Eps Diluted 2023'] > 0) & (df['Eps Diluted 2024'] > 0)]\n",
    "filtered_df=filtered_df[filtered_df['reason'].isna()]\n",
    "# filtered_df=filtered_df.dropna(subset=['reason'])\n",
    "filtered_df=filtered_df[['Stock Name', 'Symbol', 'Price','PE Ratio','Return on Equity (ttm)','EPS(TTM)','Eps Diluted 2020','Eps Diluted 2021','Eps Diluted 2022','Eps Diluted 2023','Eps Diluted 2024','Graham Formula / Intrinsic value using EPS','Over/Undervalue %','High','Median','Low','Last','Sym','Anal']]\n",
    "with pd.ExcelWriter(excel_file) as writer:\n",
    "    # Write the filtered DataFrame to a new sheet named 'PositiveData'\n",
    "    filtered_df.to_excel(writer, sheet_name='Sheet 1', index=False)\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#Sheet 2\n",
    "#--------------------------------------DCF Analysis----------------------------#\n",
    "selected_columns_df = df[df['reason'].isna()]\n",
    "# selected_columns_df = df\n",
    "selected_columns_df = df[df['Price per share(Intrinsic Value via DCF)'].notna()]\n",
    "selected_columns_df = selected_columns_df[['Stock Name', 'Symbol', 'Price','PE Ratio','Return on Equity (ttm)','FCF 2020','FCF 2021','FCF 2022','FCF 2023','Share Outstandings','Perpetual Growth rate','WACC','FFCF 2024','FFCF 2025','FFCF 2026','FFCF 2027','FFCF 2028','Terminal Value','PV of FFCF 2024','PV of FFCF 2025','PV of FFCF 2026','PV of FFCF 2027','PV of FFCF 2028','PV of Terminal Value','Sum of PV of FFCF','Cash/ Cash Equivalent','Total Debt','Equity Value','Price per share(Intrinsic Value via DCF)','High','Median','Low','Last','Sym','Anal']]\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter(excel_file,mode='a') as writer:\n",
    "    # Write the selected columns to a new sheet named 'SelectedColumns'\n",
    "    selected_columns_df.to_excel(writer, sheet_name='Sheet 2', index=False)\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "#Sheet 3\n",
    "#--------------------------------Best Line Method---------------------------#\n",
    "# df_bl=df_bl.dropna(subset=['reason'])\n",
    "df_bl=df_bl[(df_bl['reason'].isna())|(df_bl['reason']=='negative EPS')]\n",
    "selected_columns_df1 = df_bl[['Stock Name', 'Symbol', 'Price','PE Ratio','Return on Equity (ttm)','FCF 2020','FCF 2021','FCF 2022','FCF 2023','Share Outstandings','Perpetual Growth rate','WACC','FFCF 2024','FFCF 2025','FFCF 2026','FFCF 2027','FFCF 2028','Terminal Value','PV of FFCF 2024','PV of FFCF 2025','PV of FFCF 2026','PV of FFCF 2027','PV of FFCF 2028','PV of Terminal Value','Sum of PV of FFCF','Cash/ Cash Equivalent','Total Debt','Equity Value','M','Price per share(Intrinsic Value via DCF)','High','Median','Low','Last','Sym','Anal']]\n",
    "selected_columns_df1.rename(columns={'Price per share(Intrinsic Value via DCF)': 'Price per share(Intrinsic Value via BLM)'}, inplace=True)\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter(excel_file,mode='a') as writer:\n",
    "    # Write the selected columns to a new sheet named 'SelectedColumns'\n",
    "    selected_columns_df1.to_excel(writer, sheet_name='Sheet 3', index=False)\n",
    "#----------------------------------------------------------------------------#\n",
    "\n",
    "#Sheet 4\n",
    "#---------------------------Comparison sheet---------------------------------#\n",
    "sheet_names = ['Sheet 1', 'Sheet 2', 'Sheet 3']\n",
    "dfs = [pd.read_excel(excel_file, sheet_name=name) for name in sheet_names]\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i]=dfs[i].drop_duplicates()\n",
    "combined_df = pd.concat([dfs[0][['Symbol','Graham Formula / Intrinsic value using EPS']].set_index('Symbol'), dfs[1][['Symbol','Price per share(Intrinsic Value via DCF)']].set_index('Symbol'), dfs[2][['Symbol','Stock Name','Price','PE Ratio','Return on Equity (ttm)','Price per share(Intrinsic Value via BLM)']].set_index('Symbol')], axis=1)\n",
    "combined_df.reset_index(inplace=True)\n",
    "combined_df=combined_df[['Symbol','Stock Name','Price','PE Ratio','Return on Equity (ttm)','Graham Formula / Intrinsic value using EPS','Price per share(Intrinsic Value via DCF)','Price per share(Intrinsic Value via BLM)']]\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name='Sheet 4', index=False)\n",
    "#Sheet 5\n",
    "#-----------------------------RAW DATA------------------------------------#\n",
    "with pd.ExcelWriter(excel_file, mode='a') as writer:\n",
    "    columns_except_column_to_move = [col for col in df.columns if col != 'reason']\n",
    "\n",
    "    # Reorder the columns putting 'column_to_move' last\n",
    "    new_columns_order = columns_except_column_to_move + ['reason']\n",
    "\n",
    "    # Create a new DataFrame with the columns in the new order\n",
    "    df_reordered = df[new_columns_order]\n",
    "    df_reordered.to_excel(writer, sheet_name='RAW_DATA', index=False)\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "# Sheet 6\n",
    "#---------------------------------reasoned Data--------------------------#\n",
    "reasoned_df = df_reordered[df_reordered['reason'].notna()]\n",
    "with pd.ExcelWriter(excel_file,mode='a') as writer:\n",
    "    # Write the selected columns to a new sheet named 'SelectedColumns'\n",
    "    reasoned_df.to_excel(writer, sheet_name='Sheet 6', index=False)\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
